{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 22:52:23.735466: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from  nn.nn import NeuralNetwork as network\n",
    "from  nn import layers as layers\n",
    "from  nn import losses as losses\n",
    "from nn import activations as activations\n",
    "from nn.metrics import Metrics as metrics\n",
    "from nn import optimizers as optimizers\n",
    "\n",
    "# load MNIST Fashion dataset from keras\n",
    "\n",
    "\n",
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# normalize the data\n",
    "x_train = x_train/255.\n",
    "x_test = x_test/255.\n",
    "\n",
    "# Flatten the images\n",
    "x_train = x_train.reshape(-1, 1, 28,28)[:1000]\n",
    "x_test = x_test.reshape(-1, 1, 28,28)[:1000]\n",
    "\n",
    "y_test = y_test[:1000]\n",
    "y_train = y_train[:1000]\n",
    "\n",
    "# one-hot encode the labels\n",
    "y_oh_train = pd.get_dummies(y_train).values\n",
    "y_oh_test = pd.get_dummies(y_test).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of the Neural Network\n",
      "___________________________________________________________________________________________________________________\n",
      "Layer (type)        Neurons #      Input Shape    Output Shape   Weights shape  Bias shape        Param #\n",
      "===================================================================================================================\n",
      "Input               3              -              (3, None)      -              -                       0\n",
      "\n",
      "ConvLayer           10             (28, 28, 1)    ((26, 26, 10),)(3, 3, 1, 10)  (10, 1)               100\n",
      "\n",
      "ActivationLayer     -              activavtion    Tanh           -              -                       0\n",
      "\n",
      "MaxPool2D           -              (26, 26, 10)   ((13, 13, 10),)-              -                       0\n",
      "\n",
      "ConvLayer           7              (13, 13, 10)   ((11, 11, 7),) (3, 3, 10, 7)  (7, 1)                637\n",
      "\n",
      "ActivationLayer     -              activavtion    Tanh           -              -                       0\n",
      "\n",
      "MaxPool2D           -              (11, 11, 7)    ((5, 5, 7),)   -              -                       0\n",
      "\n",
      "FlattenLayer        -              -              -              -              -                       0\n",
      "\n",
      "DenseLayer          32             (175,)         (32,)          (32, 175)      (32, 1)              5632\n",
      "\n",
      "DenseLayer          10             (32,)          (10,)          (10, 32)       (10, 1)               330\n",
      "\n",
      "===================================================================================================================\n",
      "Total params                                                                                         6699\n",
      "Epoch 1-20 Batch 1-31 ======================> cost: 2.4132 accuracy: 0.0120 precision: 0.0608 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m digits\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39mlosses\u001b[39m.\u001b[39mCategoricalCrossentropy(), optimizer\u001b[39m=\u001b[39moptimizers\u001b[39m.\u001b[39mGradientDescent(lr\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m), initializer\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mglorot_uniform\u001b[39m\u001b[39m\"\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mprecision\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     17\u001b[0m digits\u001b[39m.\u001b[39msummary()\n\u001b[0;32m---> 18\u001b[0m digits\u001b[39m.\u001b[39;49mfit(x_train, y_oh_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n",
      "File \u001b[0;32m~/Courses/Notes/Deep-Learning-for-Mechanics-APL-745/Assignments/assign_5/nn/nn.py:424\u001b[0m, in \u001b[0;36mNeuralNetwork.fit\u001b[0;34m(self, x_train, y_train, epochs, batch_size, verbose, callback)\u001b[0m\n\u001b[1;32m    420\u001b[0m error \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_prime(\n\u001b[1;32m    421\u001b[0m     y_train[batch_start:batch_end]\u001b[39m.\u001b[39mT, output\n\u001b[1;32m    422\u001b[0m )  \u001b[39m# shape (ny , batch_size)\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mreversed\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers):\n\u001b[0;32m--> 424\u001b[0m     error \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39;49mbackward_propagation(error)\n\u001b[1;32m    426\u001b[0m \u001b[39m# return error\u001b[39;00m\n\u001b[1;32m    427\u001b[0m \n\u001b[1;32m    428\u001b[0m  \u001b[39m# Print verbose messages \u001b[39;00m\n\u001b[1;32m    429\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__verbose(y_train, x_train, \u001b[39miter\u001b[39m\u001b[39m=\u001b[39mi, batch_iter\u001b[39m=\u001b[39mj, verbo\u001b[39m=\u001b[39mverbose)\n",
      "File \u001b[0;32m~/Courses/Notes/Deep-Learning-for-Mechanics-APL-745/Assignments/assign_5/nn/layers.py:824\u001b[0m, in \u001b[0;36mMaxPool2D.backward_propagation\u001b[0;34m(self, dL_doutput)\u001b[0m\n\u001b[1;32m    822\u001b[0m                 \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m    823\u001b[0m                     mask \u001b[39m=\u001b[39m mask[height_start, width_start]\n\u001b[0;32m--> 824\u001b[0m                 dL_dinput[\n\u001b[1;32m    825\u001b[0m                     height_start :height_start\u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool_size[\u001b[39m0\u001b[39m],\n\u001b[1;32m    826\u001b[0m                     width_start :width_start\u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool_size[\u001b[39m1\u001b[39m],\n\u001b[1;32m    827\u001b[0m                     channel,\n\u001b[1;32m    828\u001b[0m                     image_,\n\u001b[1;32m    829\u001b[0m                 ] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m dL_doutput[height_start, width_start, channel, image_] \u001b[39m*\u001b[39m mask\n\u001b[1;32m    831\u001b[0m \u001b[39mreturn\u001b[39;00m dL_dinput\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "digits = network()\n",
    "\n",
    "digits.add(layers.ConvLayer(input_shape=(28,28,1), filters=10, kernel_size=(3,3), padding='valid', use_bias=True, strides=1))  \n",
    "digits.add(layers.ActivationLayer(activations.Tanh)) \n",
    "digits.add(layers.MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "digits.add(layers.ConvLayer(filters=7, kernel_size=(3,3), padding='valid', use_bias=True, strides=1))    \n",
    "digits.add(layers.ActivationLayer(activations.Tanh))\n",
    "digits.add(layers.MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "digits.add(layers.FlattenLayer())\n",
    "digits.add(layers.DenseLayer( units=32, activation=\"tanh\"))\n",
    "digits.add(layers.DenseLayer( units=10, activation=\"softmax\"))                \n",
    "\n",
    "digits.compile(loss=losses.CategoricalCrossentropy(), optimizer=optimizers.GradientDescent(lr=0.1), initializer=\"glorot_uniform\", metrics=[\"accuracy\", \"precision\"])\n",
    "\n",
    "digits.summary()\n",
    "digits.fit(x_train, y_oh_train, epochs=20, batch_size=32, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a4a1b8dfbfcf197657bbe13300384e076b1914ebd98f1200feef09f71d03b223"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
