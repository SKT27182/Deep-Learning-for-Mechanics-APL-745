{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from conv import Conv3x3\n",
    "from maxpool import MaxPool2\n",
    "from softmax import Softmax\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# load mnist handwritten dataset from tensorflow\n",
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images[:1000]\n",
    "train_labels = train_labels[:1000]\n",
    "test_images = test_images[:1000]\n",
    "test_labels = test_labels[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the images.\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a model \n",
    "\n",
    "conv = Conv3x3(num_filters=9)                   # 9 filters, of size 3x3 and stride 1 without padding\n",
    "pool = MaxPool2()                  # Pooling layer with size 2x2 and stride 2\n",
    "softmax = Softmax(input_len=13 * 13 * 9, nodes=10)  # Softmax layer with 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass\n",
    "def forward(image, label):\n",
    "  '''\n",
    "  Completes a forward pass of the CNN and calculates the accuracy and\n",
    "  cross-entropy loss.\n",
    "  - image is a 2d numpy array\n",
    "  - label is a digit\n",
    "  '''\n",
    "  # Transform the grayscale image from [0, 255] to [-0.5, 0.5] to make it easier\n",
    "  # to work with.\n",
    "  out = conv.forward(image )\n",
    "  out = pool.forward( out )\n",
    "  out = softmax.forward( out )\n",
    "\n",
    "  # Compute cross-entropy loss and accuracy.\n",
    "  loss =  -np.log(out[label])\n",
    "  acc =  1 if np.argmax(out) == label else 0\n",
    "\n",
    "  return out, loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(im, label, lr=.001):\n",
    "  '''\n",
    "  A training step on the given image and label.\n",
    "  Shall return the cross-entropy loss and accuracy.\n",
    "  - image is a 2d numpy array\n",
    "  - label is a digit\n",
    "  - lr is the learning rate\n",
    "  '''\n",
    "  # Forward\n",
    "  out, loss, acc = forward(im, label)\n",
    "\n",
    "  # Calculate initial gradient\n",
    "  gradient = np.zeros(10)\n",
    "  gradient[label] = -1 / out[label]\n",
    "\n",
    "  # Backprop\n",
    "  gradient = softmax.backprop(gradient, lr)\n",
    "  gradient = pool.backprop(gradient)\n",
    "  gradient = conv.backprop(gradient, lr)\n",
    "\n",
    "  return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 1 ---\n",
      "[Step 0] Past 100 steps: Average Loss 0.000 | Accuracy: 0%\n",
      "[Step 100] Past 100 steps: Average Loss 2.295 | Accuracy: 19%\n",
      "[Step 200] Past 100 steps: Average Loss 2.250 | Accuracy: 47%\n",
      "[Step 300] Past 100 steps: Average Loss 2.234 | Accuracy: 40%\n",
      "[Step 400] Past 100 steps: Average Loss 2.195 | Accuracy: 50%\n",
      "[Step 500] Past 100 steps: Average Loss 2.151 | Accuracy: 52%\n",
      "[Step 600] Past 100 steps: Average Loss 2.091 | Accuracy: 51%\n",
      "[Step 700] Past 100 steps: Average Loss 2.036 | Accuracy: 49%\n",
      "[Step 800] Past 100 steps: Average Loss 2.014 | Accuracy: 66%\n",
      "[Step 900] Past 100 steps: Average Loss 1.928 | Accuracy: 70%\n",
      "--- Epoch 2 ---\n",
      "[Step 0] Past 100 steps: Average Loss 0.000 | Accuracy: 0%\n",
      "[Step 100] Past 100 steps: Average Loss 1.720 | Accuracy: 67%\n",
      "[Step 200] Past 100 steps: Average Loss 1.619 | Accuracy: 72%\n",
      "[Step 300] Past 100 steps: Average Loss 1.487 | Accuracy: 73%\n",
      "[Step 400] Past 100 steps: Average Loss 1.276 | Accuracy: 84%\n",
      "[Step 500] Past 100 steps: Average Loss 1.307 | Accuracy: 72%\n",
      "[Step 600] Past 100 steps: Average Loss 1.204 | Accuracy: 74%\n",
      "[Step 700] Past 100 steps: Average Loss 1.088 | Accuracy: 78%\n",
      "[Step 800] Past 100 steps: Average Loss 1.100 | Accuracy: 74%\n",
      "[Step 900] Past 100 steps: Average Loss 0.865 | Accuracy: 83%\n",
      "--- Epoch 3 ---\n",
      "[Step 0] Past 100 steps: Average Loss 0.000 | Accuracy: 0%\n",
      "[Step 100] Past 100 steps: Average Loss 0.775 | Accuracy: 80%\n",
      "[Step 200] Past 100 steps: Average Loss 0.758 | Accuracy: 86%\n",
      "[Step 300] Past 100 steps: Average Loss 0.893 | Accuracy: 77%\n",
      "[Step 400] Past 100 steps: Average Loss 0.614 | Accuracy: 90%\n",
      "[Step 500] Past 100 steps: Average Loss 0.697 | Accuracy: 82%\n",
      "[Step 600] Past 100 steps: Average Loss 0.576 | Accuracy: 85%\n",
      "[Step 700] Past 100 steps: Average Loss 0.591 | Accuracy: 87%\n",
      "[Step 800] Past 100 steps: Average Loss 0.595 | Accuracy: 87%\n",
      "[Step 900] Past 100 steps: Average Loss 0.720 | Accuracy: 76%\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "for epoch in range(3):\n",
    "  print('--- Epoch %d ---' % (epoch + 1))\n",
    "\n",
    "  # Shuffle the training data\n",
    "  permutation = np.random.permutation(len(train_images))\n",
    "  train_images = train_images[permutation]\n",
    "  train_labels = train_labels[permutation]\n",
    "\n",
    "  # Train!\n",
    "  loss = 0\n",
    "  num_correct = 0\n",
    "\n",
    "  for i, (im, label) in enumerate(zip(train_images, train_labels)):\n",
    "    if i % 100 == 0:\n",
    "      print(\n",
    "        '[Step %d] Past 100 steps: Average Loss %.3f | Accuracy: %d%%' %\n",
    "        (i, loss / 100, num_correct)\n",
    "      )\n",
    "      loss = 0\n",
    "      num_correct = 0\n",
    "\n",
    "    l, acc = train(im, label)\n",
    "    loss += l\n",
    "    num_correct  += acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Set Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.862\n"
     ]
    }
   ],
   "source": [
    "loss = 0\n",
    "num_correct = 0\n",
    "for im, label in zip(train_images, train_labels):\n",
    "  _, l, acc = forward(im, label)\n",
    "  loss += l\n",
    "  num_correct += acc\n",
    "\n",
    "num_trains = len(train_images)\n",
    "print('Train Accuracy:', num_correct / num_trains)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.781\n"
     ]
    }
   ],
   "source": [
    "loss = 0\n",
    "num_correct = 0\n",
    "for im, label in zip(test_images, test_labels):\n",
    "  _, l, acc = forward(im, label)\n",
    "  loss += l\n",
    "  num_correct += acc\n",
    "\n",
    "num_tests = len(test_images)\n",
    "print('Test Accuracy:', num_correct / num_tests)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I have also written a Full Neural Netwrok Module from Scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from  nn.nn import NeuralNetwork as network\n",
    "from  nn import layers as layers\n",
    "from  nn import losses as losses\n",
    "from nn import activations as activations\n",
    "from nn.metrics import Metrics as metrics\n",
    "from nn import optimizers as optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the dimesions of the input \n",
    "x_train = train_images.reshape(-1,1,28,28)\n",
    "x_test = test_images.reshape(-1,1,28,28)\n",
    "\n",
    "# one hot encoding the y labels\n",
    "y_train = pd.get_dummies(train_labels).values\n",
    "y_test = pd.get_dummies(test_labels).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of the Neural Network\n",
      "___________________________________________________________________________________________________________________\n",
      "Layer (type)        Neurons #      Input Shape    Output Shape   Weights shape  Bias shape        Param #\n",
      "===================================================================================================================\n",
      "Input               3              -              (3, None)      -              -                       0\n",
      "\n",
      "ConvLayer           9              (28, 28, 1)    ((26, 26, 9),) (3, 3, 1, 9)   (9, 1)                 90\n",
      "\n",
      "MaxPool2D           -              (26, 26, 9)    ((13, 13, 9),) -              -                       0\n",
      "\n",
      "FlattenLayer        -              -              -              -              -                       0\n",
      "\n",
      "DenseLayer          10             (1521,)        (10,)          (10, 1521)     (10, 1)             15220\n",
      "\n",
      "===================================================================================================================\n",
      "Total params                                                                                        15310\n",
      "Epoch 1-10 ======================> cost: 0.9918 accuracy: 0.7140 precision: 0.7293 \n",
      "Epoch 2-10 ======================> cost: 0.7775 accuracy: 0.7690 precision: 0.7856 \n",
      "Epoch 3-10 ======================> cost: 0.6286 accuracy: 0.8140 precision: 0.8083 \n",
      "Epoch 4-10 ======================> cost: 0.5774 accuracy: 0.8360 precision: 0.8405 \n",
      "Epoch 5-10 ======================> cost: 0.4826 accuracy: 0.8620 precision: 0.8603 \n",
      "Epoch 6-10 ======================> cost: 0.4560 accuracy: 0.8630 precision: 0.8642 \n",
      "Epoch 7-10 ======================> cost: 0.3699 accuracy: 0.8910 precision: 0.8903 \n",
      "Epoch 8-10 ======================> cost: 0.3656 accuracy: 0.8850 precision: 0.8869 \n",
      "Epoch 9-10 ======================> cost: 0.3215 accuracy: 0.9050 precision: 0.9080 \n",
      "Epoch 10-10 ======================> cost: 0.2914 accuracy: 0.9220 precision: 0.9210 \n"
     ]
    }
   ],
   "source": [
    "digits = network()\n",
    "\n",
    "digits.add(layers.ConvLayer(input_shape=(28,28,1), filters=9, kernel_size=(3,3), padding='valid', use_bias=True, strides=1))  \n",
    "digits.add(layers.MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "\n",
    "digits.add(layers.FlattenLayer())\n",
    "digits.add(layers.DenseLayer( units=10, activation=\"softmax\"))                \n",
    "\n",
    "digits.compile(loss=losses.CategoricalCrossentropy(), optimizer=optimizers.Adam(lr=0.01), initializer=\"glorot_uniform\", metrics=[\"accuracy\", \"precision\"])\n",
    "\n",
    "digits.summary()\n",
    "digits.fit(x_train, y_train, epochs=10, batch_size=32, verbose=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Set Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.922\n"
     ]
    }
   ],
   "source": [
    "pred_train_preb = digits.predict(x_train)\n",
    "\n",
    "# get the index of the max value in each column\n",
    "pred_train = np.argmax(pred_train_preb, axis=1)\n",
    "y_train_ = np.argmax(y_train, axis=1)\n",
    "print(\"Train Accuracy: \", metrics.accuracy(y_train_, pred_train))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.753\n"
     ]
    }
   ],
   "source": [
    "pred_test_preb = digits.predict(x_test)\n",
    "\n",
    "# get the index of the max value in each column\n",
    "pred_test = np.argmax(pred_test_preb, axis=1)\n",
    "y_test_ = np.argmax(y_test, axis=1)\n",
    "print(\"Test Accuracy: \", metrics.accuracy(y_test_, pred_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a4a1b8dfbfcf197657bbe13300384e076b1914ebd98f1200feef09f71d03b223"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
