{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 23:14:11.232703: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from conv import Conv3x3\n",
    "from maxpool import MaxPool2\n",
    "from softmax import Softmax\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# load mnist handwritten dataset from tensorflow\n",
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images[:1000]\n",
    "train_labels = train_labels[:1000]\n",
    "test_images = test_images[:1000]\n",
    "test_labels = test_labels[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the images.\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a model \n",
    "\n",
    "conv = Conv3x3(num_filters=9)                   # 9 filters, of size 3x3 and stride 1 without padding\n",
    "pool = MaxPool2()                  # Pooling layer with size 2x2 and stride 2\n",
    "softmax = Softmax(input_len=13 * 13 * 9, nodes=10)  # Softmax layer with 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass\n",
    "def forward(image, label):\n",
    "  '''\n",
    "  Completes a forward pass of the CNN and calculates the accuracy and\n",
    "  cross-entropy loss.\n",
    "  - image is a 2d numpy array\n",
    "  - label is a digit\n",
    "  '''\n",
    "  # Transform the grayscale image from [0, 255] to [-0.5, 0.5] to make it easier\n",
    "  # to work with.\n",
    "  out = conv.forward(image )\n",
    "  out = pool.forward( out )\n",
    "  out = softmax.forward( out )\n",
    "\n",
    "  # Compute cross-entropy loss and accuracy.\n",
    "  loss =  -np.log(out[label])\n",
    "  acc =  1 if np.argmax(out) == label else 0\n",
    "\n",
    "  return out, loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(im, label, lr=.001):\n",
    "  '''\n",
    "  A training step on the given image and label.\n",
    "  Shall return the cross-entropy loss and accuracy.\n",
    "  - image is a 2d numpy array\n",
    "  - label is a digit\n",
    "  - lr is the learning rate\n",
    "  '''\n",
    "  # Forward\n",
    "  out, loss, acc = forward(im, label)\n",
    "\n",
    "  # Calculate initial gradient\n",
    "  gradient = np.zeros(10)\n",
    "  gradient[label] = -1 / out[label]\n",
    "\n",
    "  # Backprop\n",
    "  gradient = softmax.backprop(gradient, lr)\n",
    "  gradient = pool.backprop(gradient)\n",
    "  gradient = conv.backprop(gradient, lr)\n",
    "\n",
    "  return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 1 ---\n",
      "[Step 0] Past 100 steps: Average Loss 0.000 | Accuracy: 0%\n",
      "[Step 100] Past 100 steps: Average Loss 2.294 | Accuracy: 25%\n",
      "[Step 200] Past 100 steps: Average Loss 2.270 | Accuracy: 33%\n",
      "[Step 300] Past 100 steps: Average Loss 2.256 | Accuracy: 38%\n",
      "[Step 400] Past 100 steps: Average Loss 2.235 | Accuracy: 38%\n",
      "[Step 500] Past 100 steps: Average Loss 2.208 | Accuracy: 49%\n",
      "[Step 600] Past 100 steps: Average Loss 2.178 | Accuracy: 60%\n",
      "[Step 700] Past 100 steps: Average Loss 2.141 | Accuracy: 67%\n",
      "[Step 800] Past 100 steps: Average Loss 2.110 | Accuracy: 66%\n",
      "[Step 900] Past 100 steps: Average Loss 2.055 | Accuracy: 64%\n",
      "--- Epoch 2 ---\n",
      "[Step 0] Past 100 steps: Average Loss 0.000 | Accuracy: 0%\n",
      "[Step 100] Past 100 steps: Average Loss 1.931 | Accuracy: 64%\n",
      "[Step 200] Past 100 steps: Average Loss 1.790 | Accuracy: 72%\n",
      "[Step 300] Past 100 steps: Average Loss 1.702 | Accuracy: 63%\n",
      "[Step 400] Past 100 steps: Average Loss 1.517 | Accuracy: 72%\n",
      "[Step 500] Past 100 steps: Average Loss 1.484 | Accuracy: 72%\n",
      "[Step 600] Past 100 steps: Average Loss 1.358 | Accuracy: 79%\n",
      "[Step 700] Past 100 steps: Average Loss 1.284 | Accuracy: 79%\n",
      "[Step 800] Past 100 steps: Average Loss 1.181 | Accuracy: 78%\n",
      "[Step 900] Past 100 steps: Average Loss 1.067 | Accuracy: 79%\n",
      "--- Epoch 3 ---\n",
      "[Step 0] Past 100 steps: Average Loss 0.000 | Accuracy: 0%\n",
      "[Step 100] Past 100 steps: Average Loss 0.885 | Accuracy: 86%\n",
      "[Step 200] Past 100 steps: Average Loss 0.975 | Accuracy: 74%\n",
      "[Step 300] Past 100 steps: Average Loss 0.828 | Accuracy: 84%\n",
      "[Step 400] Past 100 steps: Average Loss 0.802 | Accuracy: 82%\n",
      "[Step 500] Past 100 steps: Average Loss 0.771 | Accuracy: 80%\n",
      "[Step 600] Past 100 steps: Average Loss 0.670 | Accuracy: 83%\n",
      "[Step 700] Past 100 steps: Average Loss 0.744 | Accuracy: 79%\n",
      "[Step 800] Past 100 steps: Average Loss 0.679 | Accuracy: 86%\n",
      "[Step 900] Past 100 steps: Average Loss 0.501 | Accuracy: 89%\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "for epoch in range(3):\n",
    "  print('--- Epoch %d ---' % (epoch + 1))\n",
    "\n",
    "  # Shuffle the training data\n",
    "  permutation = np.random.permutation(len(train_images))\n",
    "  train_images = train_images[permutation]\n",
    "  train_labels = train_labels[permutation]\n",
    "\n",
    "  # Train!\n",
    "  loss = 0\n",
    "  num_correct = 0\n",
    "\n",
    "  for i, (im, label) in enumerate(zip(train_images, train_labels)):\n",
    "    if i % 100 == 0:\n",
    "      print(\n",
    "        '[Step %d] Past 100 steps: Average Loss %.3f | Accuracy: %d%%' %\n",
    "        (i, loss / 100, num_correct)\n",
    "      )\n",
    "      loss = 0\n",
    "      num_correct = 0\n",
    "\n",
    "    l, acc = train(im, label)\n",
    "    loss += l\n",
    "    num_correct  += acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Set Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.851\n"
     ]
    }
   ],
   "source": [
    "loss = 0\n",
    "num_correct = 0\n",
    "for im, label in zip(train_images, train_labels):\n",
    "  _, l, acc = forward(im, label)\n",
    "  loss += l\n",
    "  num_correct += acc\n",
    "\n",
    "num_trains = len(train_images)\n",
    "print('Train Accuracy:', num_correct / num_trains)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "loss = 0\n",
    "num_correct = 0\n",
    "for im, label in zip(test_images, test_labels):\n",
    "  _, l, acc = forward(im, label)\n",
    "  loss += l\n",
    "  num_correct += acc\n",
    "\n",
    "num_tests = len(test_images)\n",
    "print('Test Accuracy:', num_correct / num_tests)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I have also written a Full Neural Netwrok Module from Scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from  nn.nn import NeuralNetwork as network\n",
    "from  nn import layers as layers\n",
    "from  nn import losses as losses\n",
    "from nn import activations as activations\n",
    "from nn.metrics import Metrics as metrics\n",
    "from nn import optimizers as optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the dimesions of the input \n",
    "x_train = train_images.reshape(-1,1,28,28)\n",
    "x_test = test_images.reshape(-1,1,28,28)\n",
    "\n",
    "# one hot encoding the y labels\n",
    "y_train = pd.get_dummies(train_labels).values\n",
    "y_test = pd.get_dummies(test_labels).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of the Neural Network\n",
      "___________________________________________________________________________________________________________________\n",
      "Layer (type)        Neurons #      Input Shape    Output Shape   Weights shape  Bias shape        Param #\n",
      "===================================================================================================================\n",
      "Input               3              -              (3, None)      -              -                       0\n",
      "\n",
      "ConvLayer           9              (28, 28, 1)    ((26, 26, 9),) (3, 3, 1, 9)   (9, 1)                 90\n",
      "\n",
      "ActivationLayer     -              activavtion    Tanh           -              -                       0\n",
      "\n",
      "MaxPool2D           -              (26, 26, 9)    ((13, 13, 9),) -              -                       0\n",
      "\n",
      "FlattenLayer        -              -              -              -              -                       0\n",
      "\n",
      "DenseLayer          10             (1521,)        (10,)          (10, 1521)     (10, 1)             15220\n",
      "\n",
      "===================================================================================================================\n",
      "Total params                                                                                        15310\n",
      "Epoch 1-20 Batch 1-31 ======================> cost: 2.2395 accuracy: 0.1740 precision: 0.1375 \n",
      "Epoch 2-20 Batch 1-31 ======================> cost: 0.9249 accuracy: 0.7170 precision: 0.7192 \n",
      "Epoch 3-20 Batch 1-31 ======================> cost: 0.7180 accuracy: 0.7830 precision: 0.7845 \n",
      "Epoch 4-20 Batch 1-31 ======================> cost: 0.5622 accuracy: 0.8490 precision: 0.8468 \n",
      "Epoch 5-20 Batch 1-31 ======================> cost: 0.5028 accuracy: 0.8340 precision: 0.8389 \n",
      "Epoch 6-20 Batch 1-31 ======================> cost: 0.4146 accuracy: 0.8820 precision: 0.8796 \n",
      "Epoch 7-20 Batch 1-31 ======================> cost: 0.3885 accuracy: 0.8850 precision: 0.8855 \n",
      "Epoch 8-20 Batch 1-31 ======================> cost: 0.3201 accuracy: 0.9210 precision: 0.9218 \n",
      "Epoch 9-20 Batch 1-31 ======================> cost: 0.3131 accuracy: 0.9080 precision: 0.9158 \n",
      "Epoch 10-20 Batch 1-31 ======================> cost: 0.2799 accuracy: 0.9290 precision: 0.9298 \n",
      "Epoch 11-20 Batch 1-31 ======================> cost: 0.2586 accuracy: 0.9310 precision: 0.9289 \n",
      "Epoch 12-20 Batch 1-31 ======================> cost: 0.2379 accuracy: 0.9360 precision: 0.9378 \n",
      "Epoch 13-20 Batch 1-31 ======================> cost: 0.2383 accuracy: 0.9350 precision: 0.9355 \n",
      "Epoch 14-20 Batch 1-31 ======================> cost: 0.2162 accuracy: 0.9510 precision: 0.9517 \n",
      "Epoch 15-20 Batch 1-31 ======================> cost: 0.2128 accuracy: 0.9460 precision: 0.9466 \n",
      "Epoch 16-20 Batch 1-31 ======================> cost: 0.1783 accuracy: 0.9590 precision: 0.9600 \n",
      "Epoch 17-20 Batch 1-31 ======================> cost: 0.1619 accuracy: 0.9620 precision: 0.9636 \n",
      "Epoch 18-20 Batch 1-31 ======================> cost: 0.1697 accuracy: 0.9630 precision: 0.9622 \n",
      "Epoch 19-20 Batch 1-31 ======================> cost: 0.1565 accuracy: 0.9610 precision: 0.9622 \n",
      "Epoch 20-20 Batch 1-31 ======================> cost: 0.1272 accuracy: 0.9770 precision: 0.9768 \n"
     ]
    }
   ],
   "source": [
    "digits = network()\n",
    "\n",
    "digits.add(layers.ConvLayer(input_shape=(28,28,1), filters=9, kernel_size=(3,3), padding='valid', use_bias=True, strides=1))  \n",
    "digits.add(layers.ActivationLayer(activations.Tanh)) \n",
    "digits.add(layers.MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "\n",
    "digits.add(layers.FlattenLayer())\n",
    "digits.add(layers.DenseLayer( units=10, activation=\"softmax\"))                \n",
    "\n",
    "digits.compile(loss=losses.CategoricalCrossentropy(), optimizer=optimizers.Adam(lr=0.01), initializer=\"glorot_uniform\", metrics=[\"accuracy\", \"precision\"])\n",
    "\n",
    "digits.summary()\n",
    "digits.fit(x_train, y_train, epochs=20, batch_size=32, verbose=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Set Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.977\n"
     ]
    }
   ],
   "source": [
    "pred_train_preb = digits.predict(x_train)\n",
    "\n",
    "# get the index of the max value in each column\n",
    "pred_train = np.argmax(pred_train_preb, axis=1)\n",
    "y_train_ = np.argmax(y_train, axis=1)\n",
    "print(\"Train Accuracy: \", metrics.accuracy(y_train_, pred_train))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.766\n"
     ]
    }
   ],
   "source": [
    "pred_test_preb = digits.predict(x_test)\n",
    "\n",
    "# get the index of the max value in each column\n",
    "pred_test = np.argmax(pred_test_preb, axis=1)\n",
    "y_test_ = np.argmax(y_test, axis=1)\n",
    "print(\"Test Accuracy: \", metrics.accuracy(y_test_, pred_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a4a1b8dfbfcf197657bbe13300384e076b1914ebd98f1200feef09f71d03b223"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
